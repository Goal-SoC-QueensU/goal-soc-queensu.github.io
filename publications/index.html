<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/574741585039d06e-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/578ab86435a764c2.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-fd381a4ca618f569.js"/><script src="/_next/static/chunks/8bc8d761-70f7923cc9630091.js" async=""></script><script src="/_next/static/chunks/240-49a19ec9eac8f9fc.js" async=""></script><script src="/_next/static/chunks/main-app-5d6f90d109f78853.js" async=""></script><script src="/_next/static/chunks/41-75db50687ff393bf.js" async=""></script><script src="/_next/static/chunks/464-9177dc8afae7cdd4.js" async=""></script><script src="/_next/static/chunks/123-678ca1856f9703a7.js" async=""></script><script src="/_next/static/chunks/582-65a37c7ba111cf05.js" async=""></script><script src="/_next/static/chunks/app/publications/page-98e2af343047d25e.js" async=""></script><script src="/_next/static/chunks/204-9c2b39d1f3f24a53.js" async=""></script><script src="/_next/static/chunks/app/layout-56105fa9317b272f.js" async=""></script><script src="/_next/static/chunks/app/page-1ec51f3aee49fe8d.js" async=""></script><title>GOAL Lab - Queen&#x27;s University</title><meta name="description" content="Global Optimization, Analytics, and Learning Lab at Queen&#x27;s University. Shaping the future in resource allocation, healthcare, autonomous vehicles, and quantum algorithms."/><meta name="author" content="GOAL Lab"/><meta name="generator" content="v0.dev"/><meta name="keywords" content="optimization,analytics,machine learning,research,queens university"/><meta property="og:title" content="GOAL Lab - Queen&#x27;s University"/><meta property="og:description" content="Global Optimization, Analytics, and Learning Lab at Queen&#x27;s University"/><meta property="og:site_name" content="GOAL Lab"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="GOAL Lab - Queen&#x27;s University"/><meta name="twitter:description" content="Global Optimization, Analytics, and Learning Lab at Queen&#x27;s University"/><link rel="icon" href="/favicon.ico"/><link rel="apple-touch-icon" href="/favicon.ico"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_e8ce0c __variable_bfdd57 font-sans antialiased dark"><div class="min-h-screen flex flex-col"><header class="sticky top-0 z-50 w-full border-b transition-all duration-300 bg-transparent"><div class="container mx-auto px-4"><div class="flex h-16 items-center justify-between"><div class="flex items-center space-x-2"><a href="/"><img alt="GOAL Lab Logo" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="h-8 w-auto" style="color:transparent" src="/images/goal_logo_black.png"/></a><a class="font-bold text-xl" href="/">GOAL Lab</a></div><nav class="hidden md:flex items-center space-x-8 text-lg md:text-xl"><a class="font-medium transition-colors hover:text-primary text-muted-foreground" href="/">Home</a><a class="font-medium transition-colors hover:text-primary text-muted-foreground" href="/research/">Research</a><a class="font-medium transition-colors hover:text-primary text-muted-foreground" href="/publications/">Publications</a><a class="font-medium transition-colors hover:text-primary text-muted-foreground" href="/news/">News</a><a class="font-medium transition-colors hover:text-primary text-muted-foreground" href="/people/">People</a><a class="font-medium transition-colors hover:text-primary text-muted-foreground" href="/about/">About Us</a></nav><div class="hidden md:flex items-center"><a href="https://www.cs.queensu.ca/"><img alt="Queen’s Computing" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="h-12 w-auto" style="color:transparent" src="/images/QSC-logo-lockup.png"/></a></div><div class="flex items-center space-x-4"><button class="inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground h-10 w-10 md:hidden" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rhcq:" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-menu h-5 w-5"><line x1="4" x2="20" y1="12" y2="12"></line><line x1="4" x2="20" y1="6" y2="6"></line><line x1="4" x2="20" y1="18" y2="18"></line></svg><span class="sr-only">Toggle menu</span></button></div></div></div></header><main class="flex-1"><div class="container mx-auto px-4 py-16"><div style="opacity:0;transform:translateY(50px)"><div class="text-center mb-12"><h1 class="text-4xl font-bold mb-4">Publications</h1><p class="text-xl text-muted-foreground max-w-3xl mx-auto">Discover our latest research publications and contributions to the scientific community.</p></div></div><div><div style="opacity:0;transform:translateY(50px)"><div class="mb-8 space-y-4"><div class="relative"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-search absolute left-3 top-1/2 -translate-y-1/2 w-4 h-4 text-muted-foreground"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg><input class="flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 pl-10" placeholder="Search publications…" value=""/></div><div><h3 class="text-lg font-semibold mb-4">Filter by Topic:</h3><div class="flex flex-wrap gap-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Large Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Code Generation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Network Simulation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">ns-3</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Linear Programming</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Retrieval-Augmented Generation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Gurobi Solver</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Natural Language Processing</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Optimization</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Operations Research</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Fine-tuning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Artificial Intelligence</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Computer vision</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Deep learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Intelligent systems</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Vehicle-to-infrastructure</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Generative Artificial Intelligence</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">e-health</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Synthetic Data</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Diffusion</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Conference Scheduling</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">NLP</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">CSP</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Telecommunications</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">Zero-shot</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">mental-wellbeing</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">llm</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground cursor-pointer hover:bg-primary/80">GenAI</div></div></div></div></div><div class="space-y-8"><div style="opacity:0;transform:translateY(50px)"><div data-state="open"><button class="inline-flex items-center whitespace-nowrap rounded-md ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground w-full justify-start text-2xl font-bold p-0 h-auto" type="button" aria-controls="radix-:R2d9uucq:" aria-expanded="true" data-state="open">2025<!-- --> (<!-- -->5<!-- -->)</button><div data-state="open" id="radix-:R2d9uucq:" class="space-y-4 mt-4"><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">SIMCODE: A Benchmark for Natural Language to ns-3 Network Simulation Code Generation</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Mirza Mohammad Azwad, Salimur Choudhury</span><br/><span class="text-sm"><b><em>The 50th IEEE Conference on Local Computer Networks (LCN)</em></b></span></p></div><div class="flex gap-2"><a href="" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Ra9md9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Large Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Code Generation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Network Simulation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">ns-3</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Salimur Choudhury</span><br/><span class="text-sm"><b><em>The 19th Learning and Intelligent Optimization Conference (LION 19)</em></b></span></p></div><div class="flex gap-2"><a href="https://arxiv.org/abs/2505.01485" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Raamd9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Linear Programming</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Large Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Code Generation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Retrieval-Augmented Generation</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Gurobi Solver</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">An Integrated Approach to AI-Generated Content in e-health</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Salimur Choudhury</span><br/><span class="text-sm"><b><em>The 2025 IEEE International Conference on Communications (ICC 2025)</em></b></span></p></div><div class="flex gap-2"><a href="https://arxiv.org/abs/2501.16348" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rabmd9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Generative Artificial Intelligence</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">e-health</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Synthetic Data</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Large Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Diffusion</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">Personalized Mental Health Assistance with Large Language Models</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Fozle Rabbi Shafi, M. Anwar Hossain, Salimur Choudhury</span><br/><span class="text-sm"><b><em>IEEE Computers, Software, and Applications Conference (COMPSAC) 2025</em></b></span></p></div><div class="flex gap-2"><a href="" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Racmd9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">mental-wellbeing</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">llm</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">GenAI</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">OPT2CODE: A Retrieval-Augmented Framework for Solving Linear Programming Problems</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Salimur Choudhury</span><br/><span class="text-sm"><b><em>Artificial Intelligence and Machine Learning in Operations Management Research (AIMOR) Workshop 2025</em></b></span></p></div><div class="flex gap-2"><a href="" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Radmd9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"></div></div></div></div></div></div><div style="opacity:0;transform:translateY(50px)"><div data-state="open"><button class="inline-flex items-center whitespace-nowrap rounded-md ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 hover:bg-accent hover:text-accent-foreground w-full justify-start text-2xl font-bold p-0 h-auto" type="button" aria-controls="radix-:R2l9uucq:" aria-expanded="true" data-state="open">2024<!-- --> (<!-- -->4<!-- -->)</button><div data-state="open" id="radix-:R2l9uucq:" class="space-y-4 mt-4"><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">LM4OPT: Unveiling the potential of Large Language Models in formulating mathematical optimization problems</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Salimur Choudhury</span><br/><span class="text-sm"><b><em>INFOR: Information Systems and Operational Research</em></b></span></p></div><div class="flex gap-2"><a href="https://doi.org/10.1080/03155986.2024.2388452" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Ra9ml9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Natural Language Processing</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Large Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Optimization</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Operations Research</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Fine-tuning</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">Redefining Real-time Road Quality Analysis with Vision Transformers on Edge Devices</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Naveed Ejaz, Salimur Choudhury</span><br/><span class="text-sm"><b><em>IEEE Transactions on Artificial Intelligence</em></b></span></p></div><div class="flex gap-2"><a href="https://doi.org/10.1109/TAI.2024.3394797" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Raaml9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Artificial Intelligence</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Computer vision</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Deep learning</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Intelligent systems</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Vehicle-to-infrastructure</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">Automated Scheduling for Thematic Coherence in Conferences</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Mahzabeen Emu, Tasnim Ahmed, Salimur Choudhury</span><br/><span class="text-sm"><b><em>ACM International Conference on AI-Powered Software (AIware 2024)</em></b></span></p></div><div class="flex gap-2"><a href="https://doi.org/10.1145/3664646.3665085" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rabml9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Conference Scheduling</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">NLP</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">CSP</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Language Models</div></div></div></div><div class="rounded-lg border bg-card text-card-foreground shadow-sm hover:shadow-md transition-shadow"><div class="flex flex-col space-y-1.5 p-6"><div class="flex justify-between gap-4"><div class="flex-1"><h3 class="font-semibold tracking-tight text-lg mb-2">Linguistic Intelligence in Large Language Models for Telecommunications</h3><p class="text-muted-foreground text-base">by <span class="font-medium">Tasnim Ahmed, Nicola Piovesan, Antonio De Domenico, Salimur Choudhury</span><br/><span class="text-sm"><b><em>IEEE International Conference on Communications Workshops (ICC Workshops 2024)</em></b></span></p></div><div class="flex gap-2"><a href="https://doi.org/10.1109/ICCWorkshops59551.2024.10615609" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link w-4 h-4 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>PDF</a><button class="inline-flex items-center justify-center whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-9 rounded-md px-3" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Racml9uucq:" data-state="closed">Details</button></div></div><div class="flex flex-wrap gap-2 mt-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Natural Language Processing</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Large Language Models</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Telecommunications</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80 text-xs">Zero-shot</div></div></div></div></div></div></div></div></div></div></main><footer class="border-t bg-background"><div class="container mx-auto px-4 py-8"><div class="grid grid-cols-1 md:grid-cols-3 gap-8"><div><h3 class="font-bold text-lg mb-4">GOAL Lab</h3><p class="text-sm text-muted-foreground mb-4">Global Optimization, Analytics, and Learning Lab</p><div class="flex space-x-4"><a class="text-muted-foreground hover:text-primary" href="https://scholar.google.ca/citations?user=EzCD7v0AAAAJ&amp;hl=en&amp;oi=ao"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-graduation-cap h-5 w-5"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z"></path><path d="M22 10v6"></path><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"></path></svg><span class="sr-only">Google Scholar</span></a><a class="text-muted-foreground hover:text-primary" href="mailto:goal.cs.queensu@gmail.com"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-5 w-5"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg><span class="sr-only">Email</span></a></div></div><div><h4 class="font-semibold mb-4">Quick Links</h4><ul class="space-y-2 text-sm"><li><a class="text-muted-foreground hover:text-primary" href="/research/">Research</a></li><li><a class="text-muted-foreground hover:text-primary" href="/publications/">Publications</a></li><li><a class="text-muted-foreground hover:text-primary" href="/news/">News</a></li><li><a class="text-muted-foreground hover:text-primary" href="/people/">People</a></li><li><a class="text-muted-foreground hover:text-primary" href="/about/">About Us</a></li></ul></div><div><h4 class="font-semibold mb-4">Contact</h4><div class="text-sm text-muted-foreground space-y-2"><p>School of Computing, Queen&#x27;s University</p><p>Kingston, ON, Canada</p></div></div></div><div class="border-t mt-8 pt-8 text-center text-sm text-muted-foreground"><p>© <!-- -->2025<!-- --> GOAL Lab, Queen&#x27;s University. All rights reserved. Maintained and developed by <a href="https://tasnim7ahmed.github.io/">Tasnim Ahmed</a>.</p></div></div></footer></div><section aria-label="Notifications alt+T" tabindex="-1" aria-live="polite" aria-relevant="additions text" aria-atomic="false"></section>   <script src="/_next/static/chunks/webpack-fd381a4ca618f569.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/574741585039d06e-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n3:HL[\"/_next/static/css/578ab86435a764c2.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"4:I[7266,[],\"\"]\n6:I[4119,[\"41\",\"static/chunks/41-75db50687ff393bf.js\",\"464\",\"static/chunks/464-9177dc8afae7cdd4.js\",\"123\",\"static/chunks/123-678ca1856f9703a7.js\",\"582\",\"static/chunks/582-65a37c7ba111cf05.js\",\"304\",\"static/chunks/app/publications/page-98e2af343047d25e.js\"],\"FadeInSection\"]\n7:I[2147,[\"41\",\"static/chunks/41-75db50687ff393bf.js\",\"464\",\"static/chunks/464-9177dc8afae7cdd4.js\",\"123\",\"static/chunks/123-678ca1856f9703a7.js\",\"582\",\"static/chunks/582-65a37c7ba111cf05.js\",\"304\",\"static/chunks/app/publications/page-98e2af343047d25e.js\"],\"default\"]\nf:I[2110,[],\"\"]\n10:I[4718,[],\"\"]\n11:I[9593,[\"41\",\"static/chunks/41-75db50687ff393bf.js\",\"123\",\"static/chunks/123-678ca1856f9703a7.js\",\"204\",\"static/chunks/204-9c2b39d1f3f24a53.js\",\"582\",\"static/chunks/582-65a37c7ba111cf05.js\",\"185\",\"static/chunks/app/layout-56105fa9317b272f.js\"],\"Navigation\"]\n12:I[6443,[\"41\",\"static/chunks/41-75db50687ff393bf.js\",\"464\",\"static/chunks/464-9177dc8afae7cdd4.js\",\"123\",\"static/chunks/123-678ca1856f9703a7.js\",\"204\",\"static/chunks/204-9c2b39d1f3f24a53.js\",\"931\",\"static/chunks/app/page-1ec51f3aee49fe8d.js\"],\"\"]\n13:I[582,[\"41\",\"static/chunks/41-75db50687ff393bf.js\",\"123\",\"static/chunks/123-678ca1856f9703a7.js\",\"204\",\"static/chunks/204-9c2b39d1f3f24a53.js\",\"582\",\"static/chunks/582-65a37c7ba111cf05.js\",\"185\",\"static/chunks/app/layout-56105fa9317b272f.js\"],\"Toaster\"]\n15:I[4735,[],\"\"]\n8:T48e,Large language models (LLMs) have demonstrated remarkable capabilities in code generation across various domains. However, their effectiveness in generating simulation scripts for domain-specific environments like ns-3 remains underexplored. Despite the growing interest in automating network simulations, existing tools primarily focus on interactive automation over rigorous evaluation. To facilitate systematic evaluation, we introduce SIMCODE, the first benchmark to evaluate LLMs' ability to generate ns-3 simulation code from natural language. SIMCODE includes 400 tasks across introductory, intermediate, and advanced levels, with solutions and test cases. Us"])</script><script>self.__next_f.push([1,"ing SIMCODE, we evaluate three prominent LLMs, Gemini-2.0, GPT-4.1, and Qwen-3, across six prompt techniques. Furthermore, investigating task-specific fine-tuning’s impact reveals that while GPT-4.1 outperforms others, execution accuracy remains modest, with substantial room for improvement. Error analysis identifies missing headers and API mismatches as dominant failures. Nevertheless, SIMCODE provides a foundational step toward evaluating LLMs and research in domain-aware generative systems.9:T5f6,Linear Programming (LP) problems aim to find the optimal solution to an objective under constraints. These problems typically require domain knowledge, mathematical skills, and programming ability, presenting significant challenges for non-experts. This study explores the efficiency of Large Language Models (LLMs) in generating solver-specific LP code. We propose CHORUS, a retrieval-augmented generation (RAG) framework for synthesizing Gurobi-based LP code from natural language problem statements. CHORUS incorporates a hierarchical tree-like chunking strategy for theoretical contents and generates additional metadata based on code examples from documentation to facilitate self-contained, semantically coherent retrieval. Two-stage retrieval approach of CHORUS followed by cross-encoder reranking further ensures contextual relevance. Finally, expertly crafted prompt and structured parser with reasoning steps improve code generation performance significantly. Experiments on the NL4Opt-Code benchmark show that CHORUS improves the performance of open-source LLMs such as Llama3.1 (8B), Llama3.3 (70B), Phi4 (14B), Deepseek-r1 (32B), and Qwen2.5-coder (32B) by a significant margin compared to baseline and conventional RAG. It also allows these open-source LLMs to outperform or match the performance of much stronger baselines-GPT3.5 and GPT4 while requiring far fewer computational resources. Ablation studies further demonstrate the importance of expert prompting, hierarchical chunking, and structured reasoning.a:T5d1,In the f"])</script><script>self.__next_f.push([1,"ast-paced domain of natural language processing, converting linguistic descriptions into mathematical optimization problems is a complex task, requiring profound comprehension and processing skills from Large Language Models (LLMs). In this study, various LLMs were evaluated, including GPT-3.5, GPT-4, and smaller variants with seven billion parameters: Llama-2, Falcon, Mistral, and Zephyr. This research investigated their performance in both zero-shot and one-shot settings for this task, revealing that GPT-4 outperformed others, particularly in the one-shot scenario. A core contribution of this study is the development of LM4OPT, a progressive fine-tuning framework specifically designed for smaller LLMs. This framework leverages noisy embeddings and specialized datasets to enhance the performance of the models. Regardless of the inherent limitations of smaller models in processing complex and lengthy input contexts, our experimental results indicate a significant reduction in the performance disparity between smaller and larger models when the former are fine-tuned using LM4OPT. Our empirical study, utilizing the NL4Opt dataset, unveils that GPT-4 surpasses the baseline performance established by previous research, achieving an accuracy of 63.30%, solely based on the problem description in natural language, and without relying on any additional named entity information. GPT-3.5 follows closely, both outperforming the progressively fine-tuned smaller models.b:T595,Road infrastructure is essential for transportation safety and efficiency. However, the current methods for assessing road conditions, crucial for effective planning and maintenance, suffer from high costs, time-intensive procedures, infrequent data collection, and limited real-time capabilities. This article presents an efficient lightweight system to analyze road quality from video feeds in real time. The backbone of the system is EdgeFusionViT, a novel vision transformer (ViT)-based architecture that uses an attention-based late fusion mechanism. The "])</script><script>self.__next_f.push([1,"proposed architecture outperforms lightweight convolutional neural network (CNN)-based and ViT-based models. Its practicality is demonstrated by its deployment on an edge device, the Nvidia Jetson Orin Nano, enabling real-time road analysis at 12 frames per second. EdgeFusionViT outperforms existing benchmarks, achieving an impressive accuracy of 89.76% on the road surface condition dataset (RSCD). Notably, the model maintains a commendable accuracy of 76.89% even when trained with only 2% of the dataset, demonstrating its robustness and efficiency. These findings highlight the system's potential in road infrastructure management. It aids in creating safer, more efficient transport systems through timely, accurate road condition assessments. The study sets a new benchmark and opens up possibilities for advanced machine learning in infrastructure management.c:T41d,Artificial Intelligence-Generated Content, a subset of Generative Artificial Intelligence, holds significant potential for advancing the e-health sector by generating diverse forms of data. In this paper, we propose an end-to-end class-conditioned framework that addresses the challenge of data scarcity in health applications by generating synthetic medical images and text data, evaluating on practical applications such as retinopathy detection, skin infections and mental health assessments. Our framework integrates Diffusion and Large Language Models (LLMs) to generate data that closely match real-world patterns, which is essential for improving downstream task performance and model robustness in e-health applications. Experimental results demonstrate that the synthetic images produced by the proposed diffusion model outperform traditional GAN architectures. Similarly, in the text modality, data generated by uncensored LLM achieves significantly better alignment with real-world data than censored models in replicating the authentic tone.d:T50d,Welcome to the 1st ACM International Conference on AI-Powered Software (AIware), held on 15th and 16th July 2024"])</script><script>self.__next_f.push([1," in Porto de Galinhas, Brazil co-located with the ACM International Conference on the Foundations of Software Engineering (FSE 2024). AIware aims to be an annual conference that brings the software engineering community together in anticipation of the upcoming changes driven by Foundation Models (FMs) and looks at them from the perspective of AI-powered software and their evolution. AIware 2024 prioritizes fostering discussions about the latest developments in the interdisciplinary field of AIware rather than solely focusing on the presentation of papers. The emphasis is on engaging conversations from diverse backgrounds to identify emerging research challenges and establish a new research agenda for the community in the Foundation Model era. To present papers and for discussions, the two-day conference will have five sessions themed around AIware Vision, SE for AIware, Human - AI Conversation, Security \u0026 Safety and AIware for Software Lifecycle Activities. Furthermore, the conference program will include two keynotes and five industry talks. The final session in the conference program will be dedicated to presenting accepted papers of the AIware challenge track.e:T696,Large Language Models (LLMs) have emerged as a significant advancement in the field of Natural Language Processing (NLP), demonstrating remarkable capabilities in language generation and other language-centric tasks. Despite their evaluation across a multitude of analytical and reasoning tasks in various scientific domains, a comprehensive exploration of their knowledge and understanding within the realm of natural language tasks in the telecommunications domain is still needed. This study, therefore, seeks to evaluate the knowledge and understanding capabilities of LLMs within this domain. To achieve this, we conduct an exhaustive zero-shot evaluation of four prominent LLMs—Llama-2, Falcon, Mistral, and Zephyr. These models require fewer resources than ChatGPT, making them suitable for resource-constrained environments. Their performance is comp"])</script><script>self.__next_f.push([1,"ared with state-of-the-art, fine-tuned models. To the best of our knowledge, this is the first work to extensively evaluate and compare the understanding of LLMs across multiple language-centric tasks in this domain. Our evaluation reveals that zero-shot LLMs can achieve performance levels comparable to the current state-of-the-art fine-tuned models. This indicates that pretraining on extensive text corpora equips LLMs with a degree of specialization, even within the telecommunications domain. We also observe that no single LLM consistently outperforms others, and the performance of different LLMs can fluctuate. Although their performance lags behind fine-tuned models, our findings underscore the potential of LLMs as a valuable resource for understanding various aspects of this field that lack large annotated data.16:[]\n"])</script><script>self.__next_f.push([1,"0:[\"$\",\"$L4\",null,{\"buildId\":\"OYQeyXvuTPk2Np6TW01Bf\",\"assetPrefix\":\"\",\"urlParts\":[\"\",\"publications\",\"\"],\"initialTree\":[\"\",{\"children\":[\"publications\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"publications\",{\"children\":[\"__PAGE__\",{},[[\"$L5\",[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4 py-16\",\"children\":[[\"$\",\"$L6\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"text-center mb-12\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold mb-4\",\"children\":\"Publications\"}],[\"$\",\"p\",null,{\"className\":\"text-xl text-muted-foreground max-w-3xl mx-auto\",\"children\":\"Discover our latest research publications and contributions to the scientific community.\"}]]}]}],[\"$\",\"$L7\",null,{\"publications\":[{\"title\":\"SIMCODE: A Benchmark for Natural Language to ns-3 Network Simulation Code Generation\",\"authors\":[\"Tasnim Ahmed\",\"Mirza Mohammad Azwad\",\"Salimur Choudhury\"],\"venue\":\"The 50th IEEE Conference on Local Computer Networks (LCN)\",\"link\":\"\",\"abstract\":\"$8\",\"thumbnail\":\"\",\"tags\":[\"Large Language Models\",\"Code Generation\",\"Network Simulation\",\"ns-3\"],\"year\":2025},{\"title\":\"CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code\",\"authors\":[\"Tasnim Ahmed\",\"Salimur Choudhury\"],\"venue\":\"The 19th Learning and Intelligent Optimization Conference (LION 19)\",\"link\":\"https://arxiv.org/abs/2505.01485\",\"abstract\":\"$9\",\"thumbnail\":\"chorus.png\",\"tags\":[\"Linear Programming\",\"Large Language Models\",\"Code Generation\",\"Retrieval-Augmented Generation\",\"Gurobi Solver\"],\"year\":2025},{\"title\":\"LM4OPT: Unveiling the potential of Large Language Models in formulating mathematical optimization problems\",\"authors\":[\"Tasnim Ahmed\",\"Salimur Choudhury\"],\"venue\":\"INFOR: Information Systems and Operational Research\",\"link\":\"https://doi.org/10.1080/03155986.2024.2388452\",\"abstract\":\"$a\",\"thumbnail\":\"\",\"tags\":[\"Natural Language Processing\",\"Large Language Models\",\"Optimization\",\"Operations Research\",\"Fine-tuning\"],\"year\":2024},{\"title\":\"Redefining Real-time Road Quality Analysis with Vision Transformers on Edge Devices\",\"authors\":[\"Tasnim Ahmed\",\"Naveed Ejaz\",\"Salimur Choudhury\"],\"venue\":\"IEEE Transactions on Artificial Intelligence\",\"link\":\"https://doi.org/10.1109/TAI.2024.3394797\",\"abstract\":\"$b\",\"thumbnail\":\"tai_tasnim.jpg\",\"tags\":[\"Artificial Intelligence\",\"Computer vision\",\"Deep learning\",\"Intelligent systems\",\"Vehicle-to-infrastructure\"],\"year\":2024},{\"title\":\"An Integrated Approach to AI-Generated Content in e-health\",\"authors\":[\"Tasnim Ahmed\",\"Salimur Choudhury\"],\"venue\":\"The 2025 IEEE International Conference on Communications (ICC 2025)\",\"link\":\"https://arxiv.org/abs/2501.16348\",\"abstract\":\"$c\",\"thumbnail\":\"icc_tasnim.png\",\"tags\":[\"Generative Artificial Intelligence\",\"e-health\",\"Synthetic Data\",\"Large Language Models\",\"Diffusion\"],\"year\":2025},{\"title\":\"Automated Scheduling for Thematic Coherence in Conferences\",\"authors\":[\"Mahzabeen Emu\",\"Tasnim Ahmed\",\"Salimur Choudhury\"],\"venue\":\"ACM International Conference on AI-Powered Software (AIware 2024)\",\"link\":\"https://doi.org/10.1145/3664646.3665085\",\"abstract\":\"$d\",\"thumbnail\":\"aiware_tasnim.png\",\"tags\":[\"Conference Scheduling\",\"NLP\",\"CSP\",\"Language Models\"],\"year\":2024},{\"title\":\"Linguistic Intelligence in Large Language Models for Telecommunications\",\"authors\":[\"Tasnim Ahmed\",\"Nicola Piovesan\",\"Antonio De Domenico\",\"Salimur Choudhury\"],\"venue\":\"IEEE International Conference on Communications Workshops (ICC Workshops 2024)\",\"link\":\"https://doi.org/10.1109/ICCWorkshops59551.2024.10615609\",\"abstract\":\"$e\",\"thumbnail\":\"\",\"tags\":[\"Natural Language Processing\",\"Large Language Models\",\"Telecommunications\",\"Zero-shot\"],\"year\":2024},{\"title\":\"Personalized Mental Health Assistance with Large Language Models\",\"authors\":[\"Fozle Rabbi Shafi\",\"M. Anwar Hossain\",\"Salimur Choudhury\"],\"venue\":\"IEEE Computers, Software, and Applications Conference (COMPSAC) 2025\",\"link\":\"\",\"abstract\":\"Mental health challenges continue to rise globally, yet access to effective and personalized support remains insufficient. While Large Language Models (LLMs) have shown its promise in this area, most existing solutions lack personalization, pose privacy risks, and often generate unreliable or generic responses. In this study, we present a novel approach that enhances LLM-based mental health support through fine-tuning on a combination of public and synthetically generated mental health datasets. We further propose a dynamic prompt strategy that extracts relevant mental health entities from patient conversations, such as symptoms and emotions, and retrieves relevant information from diverse data sources. We leverage function calling with Retrieval-Augmented Generation (RAG) to produce context-aware, personalized responses. Empirical comparisons with existing models demonstrate that our approach achieves higher accuracy and generates responses that are better aligned with individual user needs.\",\"thumbnail\":\"\",\"tags\":[\"mental-wellbeing\",\"llm\",\"GenAI\"],\"year\":2025},{\"title\":\"OPT2CODE: A Retrieval-Augmented Framework for Solving Linear Programming Problems\",\"authors\":[\"Tasnim Ahmed\",\"Salimur Choudhury\"],\"venue\":\"Artificial Intelligence and Machine Learning in Operations Management Research (AIMOR) Workshop 2025\",\"link\":\"\",\"abstract\":\"\",\"thumbnail\":\"\",\"tags\":[],\"year\":2025}]}]]}],null],null],null]},[null,[\"$\",\"$Lf\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"publications\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L10\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\"}]],null]},[[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/578ab86435a764c2.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_e8ce0c __variable_bfdd57 font-sans antialiased dark\",\"children\":[[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[[\"$\",\"$L11\",null,{}],[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$Lf\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L10\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[]}]}],[\"$\",\"footer\",null,{\"className\":\"border-t bg-background\",\"children\":[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4 py-8\",\"children\":[[\"$\",\"div\",null,{\"className\":\"grid grid-cols-1 md:grid-cols-3 gap-8\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h3\",null,{\"className\":\"font-bold text-lg mb-4\",\"children\":\"GOAL Lab\"}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground mb-4\",\"children\":\"Global Optimization, Analytics, and Learning Lab\"}],[\"$\",\"div\",null,{\"className\":\"flex space-x-4\",\"children\":[[\"$\",\"$L12\",null,{\"href\":\"https://scholar.google.ca/citations?user=EzCD7v0AAAAJ\u0026hl=en\u0026oi=ao\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-graduation-cap h-5 w-5\",\"children\":[[\"$\",\"path\",\"j76jl0\",{\"d\":\"M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z\"}],[\"$\",\"path\",\"1lu8f3\",{\"d\":\"M22 10v6\"}],[\"$\",\"path\",\"1r8lef\",{\"d\":\"M6 12.5V16a6 3 0 0 0 12 0v-3.5\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Google Scholar\"}]]}],[\"$\",\"$L12\",null,{\"href\":\"mailto:goal.cs.queensu@gmail.com\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":[[\"$\",\"svg\",null,{\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail h-5 w-5\",\"children\":[[\"$\",\"rect\",\"18n3k1\",{\"width\":\"20\",\"height\":\"16\",\"x\":\"2\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"1ocrg3\",{\"d\":\"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Email\"}]]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold mb-4\",\"children\":\"Quick Links\"}],[\"$\",\"ul\",null,{\"className\":\"space-y-2 text-sm\",\"children\":[[\"$\",\"li\",null,{\"children\":[\"$\",\"$L12\",null,{\"href\":\"/research\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":\"Research\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L12\",null,{\"href\":\"/publications\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":\"Publications\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L12\",null,{\"href\":\"/news\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":\"News\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L12\",null,{\"href\":\"/people\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":\"People\"}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L12\",null,{\"href\":\"/about\",\"className\":\"text-muted-foreground hover:text-primary\",\"children\":\"About Us\"}]}]]}]]}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-semibold mb-4\",\"children\":\"Contact\"}],[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground space-y-2\",\"children\":[[\"$\",\"p\",null,{\"children\":\"School of Computing, Queen's University\"}],[\"$\",\"p\",null,{\"children\":\"Kingston, ON, Canada\"}]]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"border-t mt-8 pt-8 text-center text-sm text-muted-foreground\",\"children\":[\"$\",\"p\",null,{\"children\":[\"© \",2025,\" GOAL Lab, Queen's University. All rights reserved. Maintained and developed by \",[\"$\",\"a\",null,{\"href\":\"https://tasnim7ahmed.github.io/\",\"children\":\"Tasnim Ahmed\"}],\".\"]}]}]]}]}]]}],[\"$\",\"$L13\",null,{\"position\":\"top-right\",\"richColors\":true,\"expand\":true}],\"   \"]}]}]],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L14\"],\"globalErrorComponent\":\"$15\",\"missingSlots\":\"$W16\"}]\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"GOAL Lab - Queen's University\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Global Optimization, Analytics, and Learning Lab at Queen's University. Shaping the future in resource allocation, healthcare, autonomous vehicles, and quantum algorithms.\"}],[\"$\",\"meta\",\"4\",{\"name\":\"author\",\"content\":\"GOAL Lab\"}],[\"$\",\"meta\",\"5\",{\"name\":\"generator\",\"content\":\"v0.dev\"}],[\"$\",\"meta\",\"6\",{\"name\":\"keywords\",\"content\":\"optimization,analytics,machine learning,research,queens university\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:title\",\"content\":\"GOAL Lab - Queen's University\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:description\",\"content\":\"Global Optimization, Analytics, and Learning Lab at Queen's University\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:site_name\",\"content\":\"GOAL Lab\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"GOAL Lab - Queen's University\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"Global Optimization, Analytics, and Learning Lab at Queen's University\"}],[\"$\",\"link\",\"15\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"16\",{\"rel\":\"apple-touch-icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"meta\",\"17\",{\"name\":\"next-size-adjust\"}]]\n5:null\n"])</script></body></html>